# ğŸ  House Price Prediction Project

## ğŸ“Š Dataset Overview
**Source**: Kaggle  
**Size**: 21,613 rows Ã— 21 columns  
**Key Features**:
id, date, price, bedrooms, bathrooms, sqft_living, sqft_lot, floors,
waterfront, view, condition, grade, sqft_above, sqft_basement,
yr_built, yr_renovated, zipcode, lat, long, sqft_living15, sqft_lot15

## ğŸ” Data Preprocessing Pipeline

âœ… No null values detected
ğŸ—‘ï¸ Dropped unnecessary columns
ğŸ”„ Applied transformations: cbrt(), log() for skewed data

## ğŸ“ˆ Modeling Journey

### **Phase 1: Baseline Model**
âŒ OLS Regression
âš ï¸ Issue: High correlation between independent features
â†’ Inaccurate results due to multicollinearity

### **Phase 2: Regularization Techniques**
ğŸ¯ Feature Selection Methods:

Lasso Regression

Ridge Regression

ElasticNet

ğŸ”§ Hyperparameter Tuning: GridSearchCV
âœ… Found optimal parameters for each technique

### **Phase 3: Ensemble Methods**
ğŸš€ Advanced Techniques:

Bagging methods

Boosting methods
ğŸ† XGBoost Regressor dominated with RÂ² = 87%
## ğŸ… Final Results

ğŸ¥‡ XGBoost Regressor: RÂ² = 87%
ğŸ¥ˆ Boosting Techniques: Strong performers
ğŸ¥‰ Regularization Models: Baseline improvement
## ğŸ¯ Key Takeaways
- **Correlation handling** was crucial for model stability
- **XGBoost** excelled in capturing complex patterns
- **GridSearchCV + Ensemble methods** = Winning combination

---

**Project successfully transformed raw data into a robust 87% accurate prediction model!** ğŸ‰
